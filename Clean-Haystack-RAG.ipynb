{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d69151",
   "metadata": {},
   "source": [
    "# 📚 Document Question-Answering System with Local AI\n",
    "\n",
    "This notebook creates a simple, powerful system that can read your documents and answer questions about them using:\n",
    "- **Haystack** for processing documents and finding relevant information\n",
    "- **gemma3:1b** (or any local AI model via Ollama) for generating human-like answers\n",
    "- **BM25 keyword search** for finding relevant content (no complex embeddings needed!)\n",
    "\n",
    "Perfect for working with PDFs, Word documents, and text files on your local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17d915ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required tools (this might take a minute)...\n",
      "✅ haystack-ai\n",
      "✅ haystack-ai\n",
      "✅ ollama-haystack\n",
      "✅ ollama-haystack\n",
      "✅ PyPDF2\n",
      "✅ PyPDF2\n",
      "✅ python-docx\n",
      "\n",
      "🎉 All tools installed successfully!\n",
      "✅ python-docx\n",
      "\n",
      "🎉 All tools installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install the tools we need for our RAG system\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "required_tools = [\n",
    "    \"haystack-ai\",      # Main RAG framework\n",
    "    \"ollama-haystack\",  # Connect to local Ollama models\n",
    "    \"PyPDF2\",          # Read PDF files\n",
    "    \"python-docx\"      # Read Word documents\n",
    "]\n",
    "\n",
    "print(\"Installing required tools (this might take a minute)...\")\n",
    "for tool_name in required_tools:\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", tool_name, \"-q\"])\n",
    "        print(f\"✅ {tool_name}\")\n",
    "    except:\n",
    "        print(f\"❌ {tool_name} - already installed or error\")\n",
    "\n",
    "print(\"\\n🎉 All tools installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11c63499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries loaded and ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries we need for our document Q&A system\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "# Haystack components - these handle documents and generate answers\n",
    "from haystack import Document, Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "\n",
    "# Tools for reading different types of files\n",
    "import PyPDF2  # For PDF files\n",
    "import docx    # For Word documents\n",
    "\n",
    "print(\"✅ All libraries loaded and ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9bf7457c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Creating your Document Q&A system...\n",
      "🚀 Setting up Document Q&A system with gemma3:1b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PromptBuilder has 2 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Document Q&A system is ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Create our Document Question-Answering System\n",
    "\n",
    "class DocumentQASystem:\n",
    "    \"\"\"\n",
    "    A smart system that reads your documents and answers questions about them.\n",
    "    Uses keyword search (no complex AI embeddings) and your local AI model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ai_model_name=\"gemma3:1b\"):\n",
    "        print(f\"🚀 Setting up Document Q&A system with {ai_model_name}...\")\n",
    "        \n",
    "        # Where we store all the document pieces\n",
    "        self.document_storage = InMemoryDocumentStore()\n",
    "        \n",
    "        # The components that do the actual work\n",
    "        self.document_finder = InMemoryBM25Retriever(document_store=self.document_storage)\n",
    "        self.answer_generator = OllamaGenerator(model=ai_model_name)\n",
    "        \n",
    "        # Set up the workflows for processing documents and answering questions\n",
    "        self._setup_workflows()\n",
    "        print(\"✅ Document Q&A system is ready to use!\")\n",
    "    \n",
    "    def _setup_workflows(self):\n",
    "        # Workflow for adding documents to our storage\n",
    "        self.document_adding_workflow = Pipeline()\n",
    "        self.document_adding_workflow.add_component(\"document_saver\", DocumentWriter(document_store=self.document_storage))\n",
    "        \n",
    "        # Workflow for answering questions\n",
    "        answer_template = \"\"\"Based on the provided information, answer the question clearly and helpfully.\n",
    "\n",
    "Information from documents:\n",
    "{% for document in documents %}\n",
    "{{ document.content }}\n",
    "\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ question }}\n",
    "\n",
    "Please provide a helpful answer based on the information above:\"\"\"\n",
    "        \n",
    "        self.question_answering_workflow = Pipeline()\n",
    "        self.question_answering_workflow.add_component(\"document_finder\", self.document_finder)\n",
    "        self.question_answering_workflow.add_component(\"answer_builder\", PromptBuilder(template=answer_template))\n",
    "        self.question_answering_workflow.add_component(\"answer_generator\", self.answer_generator)\n",
    "        \n",
    "        # Connect the workflow steps\n",
    "        self.question_answering_workflow.connect(\"document_finder\", \"answer_builder.documents\")\n",
    "        self.question_answering_workflow.connect(\"answer_builder\", \"answer_generator\")\n",
    "    \n",
    "    def _clean_messy_text(self, raw_text):\n",
    "        \"\"\"Clean up text from PDFs that might have weird formatting\"\"\"\n",
    "        import re\n",
    "        \n",
    "        # Fix spacing issues and normalize whitespace\n",
    "        clean_text = re.sub(r'\\s+', ' ', raw_text)\n",
    "        \n",
    "        # Remove weird characters that sometimes come from PDF conversion\n",
    "        clean_text = re.sub(r'[^\\w\\s\\.\\,\\!\\?\\;\\:\\-\\(\\)]', ' ', clean_text)\n",
    "        \n",
    "        # Only keep lines that have actual content\n",
    "        text_lines = clean_text.split('\\n')\n",
    "        meaningful_lines = []\n",
    "        for text_line in text_lines:\n",
    "            if len(text_line.strip()) > 10:  # Skip very short lines (usually junk)\n",
    "                meaningful_lines.append(text_line.strip())\n",
    "        \n",
    "        return ' '.join(meaningful_lines)\n",
    "    \n",
    "    def _break_into_smaller_pieces(self, long_text, piece_size=500, overlap_words=50):\n",
    "        \"\"\"Break long text into smaller, overlapping pieces for better searching\"\"\"\n",
    "        all_words = long_text.split()\n",
    "        text_pieces = []\n",
    "        \n",
    "        for word_index in range(0, len(all_words), piece_size - overlap_words):\n",
    "            piece_words = all_words[word_index:word_index + piece_size]\n",
    "            text_piece = ' '.join(piece_words)\n",
    "            \n",
    "            if len(text_piece.strip()) > 100:  # Only keep pieces with real content\n",
    "                text_pieces.append(text_piece)\n",
    "        \n",
    "        return text_pieces\n",
    "    \n",
    "    def add_text_content(self, text_content, source_information=None):\n",
    "        \"\"\"Add some text content to our knowledge base\"\"\"\n",
    "        if not text_content or len(text_content.strip()) < 50:\n",
    "            print(\"⚠️ Text is too short, skipping...\")\n",
    "            return\n",
    "        \n",
    "        # Clean up the text\n",
    "        cleaned_text = self._clean_messy_text(text_content)\n",
    "        \n",
    "        # Break it into smaller pieces for better searching\n",
    "        text_pieces = self._break_into_smaller_pieces(cleaned_text)\n",
    "        \n",
    "        print(f\"📝 Processing text: {len(text_content)} characters → {len(text_pieces)} searchable pieces\")\n",
    "        \n",
    "        # Add each piece as a document\n",
    "        document_pieces = []\n",
    "        for piece_number, text_piece in enumerate(text_pieces):\n",
    "            piece_information = (source_information or {}).copy()\n",
    "            piece_information['piece_number'] = piece_number + 1\n",
    "            piece_information['total_pieces'] = len(text_pieces)\n",
    "            \n",
    "            document_piece = Document(content=text_piece, meta=piece_information)\n",
    "            document_pieces.append(document_piece)\n",
    "        \n",
    "        if document_pieces:\n",
    "            self.document_adding_workflow.run({\"document_saver\": {\"documents\": document_pieces}})\n",
    "            print(f\"✅ Added {len(document_pieces)} pieces to knowledge base\")\n",
    "    \n",
    "    def add_document_file(self, file_location):\n",
    "        \"\"\"Add a file (PDF, Word doc, or text file) to our knowledge base\"\"\"\n",
    "        file_path = Path(file_location)\n",
    "        if not file_path.exists():\n",
    "            print(f\"❌ Can't find file: {file_location}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"📄 Reading {file_path.name}...\")\n",
    "        \n",
    "        try:\n",
    "            file_content = \"\"\n",
    "            if file_path.suffix.lower() == '.pdf':\n",
    "                file_content = self._extract_text_from_pdf(file_path)\n",
    "            elif file_path.suffix.lower() == '.txt':\n",
    "                file_content = file_path.read_text(encoding='utf-8', errors='ignore')\n",
    "            elif file_path.suffix.lower() == '.docx':\n",
    "                file_content = self._extract_text_from_word_doc(file_path)\n",
    "            else:\n",
    "                print(f\"❌ Don't know how to read {file_path.suffix} files\")\n",
    "                return\n",
    "            \n",
    "            if file_content and len(file_content.strip()) > 100:\n",
    "                self.add_text_content(file_content, {\"source\": str(file_path), \"filename\": file_path.name})\n",
    "            else:\n",
    "                print(f\"⚠️ Couldn't extract meaningful content from {file_path.name}\")\n",
    "        \n",
    "        except Exception as error:\n",
    "            print(f\"❌ Error reading {file_path.name}: {error}\")\n",
    "    \n",
    "    def _extract_text_from_pdf(self, pdf_file_path):\n",
    "        \"\"\"Extract text from a PDF file\"\"\"\n",
    "        extracted_content = \"\"\n",
    "        try:\n",
    "            with open(pdf_file_path, 'rb') as pdf_file:\n",
    "                pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "                for page_number, pdf_page in enumerate(pdf_reader.pages):\n",
    "                    page_content = pdf_page.extract_text()\n",
    "                    if page_content and len(page_content.strip()) > 50:\n",
    "                        extracted_content += f\"\\\\n[Page {page_number + 1}]\\\\n{page_content}\\\\n\"\n",
    "        except Exception as pdf_error:\n",
    "            print(f\"PDF reading error: {pdf_error}\")\n",
    "        return extracted_content\n",
    "    \n",
    "    def _extract_text_from_word_doc(self, word_file_path):\n",
    "        \"\"\"Extract text from a Word document\"\"\"\n",
    "        word_content = \"\"\n",
    "        try:\n",
    "            word_document = docx.Document(word_file_path)\n",
    "            for paragraph in word_document.paragraphs:\n",
    "                if paragraph.text and len(paragraph.text.strip()) > 10:\n",
    "                    word_content += paragraph.text + \"\\\\n\"\n",
    "        except Exception as word_error:\n",
    "            print(f\"Word document reading error: {word_error}\")\n",
    "        return word_content\n",
    "    \n",
    "    def answer_question(self, user_question, max_results_to_search=3):\n",
    "        \"\"\"Ask a question and get an answer based on our documents\"\"\"\n",
    "        total_document_pieces = self.document_storage.count_documents()\n",
    "        if total_document_pieces == 0:\n",
    "            return \"❌ I don't have any documents to search through yet. Please add some files first!\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"🔍 Searching through {total_document_pieces} document pieces...\")\n",
    "            \n",
    "            search_result = self.question_answering_workflow.run({\n",
    "                \"document_finder\": {\"query\": user_question, \"top_k\": max_results_to_search},\n",
    "                \"answer_builder\": {\"question\": user_question}\n",
    "            })\n",
    "            \n",
    "            generated_answer = search_result[\"answer_generator\"][\"replies\"][0]\n",
    "            return generated_answer\n",
    "            \n",
    "        except Exception as processing_error:\n",
    "            return f\"❌ Something went wrong: {processing_error}\"\n",
    "    \n",
    "    def show_knowledge_base_info(self):\n",
    "        \"\"\"Show info about what documents we have in our knowledge base\"\"\"\n",
    "        document_count = self.document_storage.count_documents()\n",
    "        print(f\"📊 Knowledge base contains {document_count} document pieces\")\n",
    "        return document_count\n",
    "\n",
    "# Create our Document Q&A system - ready to use!\n",
    "print(\"🔧 Creating your Document Q&A system...\")\n",
    "qa_system = DocumentQASystem(ai_model_name=\"gemma3:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18d9d03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Current Knowledge Base Status:\n",
      "📊 Knowledge base contains 23 document pieces\n",
      "\n",
      "💡 How to use your Document Q&A system:\n",
      "• add_document_to_system('path/to/file.pdf')     - Add a document\n",
      "• ask_about_documents('What is this about?')     - Ask questions\n",
      "• check_knowledge_base()                         - See what you have\n",
      "\n",
      "🧪 Quick test:\n",
      "❓ What documents do I currently have in my knowledge base?\n",
      "🔍 Searching through 23 document pieces...\n",
      "🤖 Based on the provided information, here’s a breakdown of the documents you currently have in your knowledge base:\n",
      "\n",
      "*   **Page 1:** Vishal Rajesh Kushwaha\n",
      "*   **Page 13:** A service of Via medici online www.thieme.de\n",
      "*   **Page 14:** Physics exam spring 2001\n",
      "*   **Page 15:** A service of Via medici online www.thieme.de\n",
      "*   **Page 16:** A service of Via medici online www.thieme.de\n",
      "*   **Page 17:** A service of Via medici online www.thieme.de\n",
      "*   **Page 18:** A service of Via medici online www.thie...\n",
      "────────────────────────────────────────────────────────────\n",
      "🤖 Based on the provided information, here’s a breakdown of the documents you currently have in your knowledge base:\n",
      "\n",
      "*   **Page 1:** Vishal Rajesh Kushwaha\n",
      "*   **Page 13:** A service of Via medici online www.thieme.de\n",
      "*   **Page 14:** Physics exam spring 2001\n",
      "*   **Page 15:** A service of Via medici online www.thieme.de\n",
      "*   **Page 16:** A service of Via medici online www.thieme.de\n",
      "*   **Page 17:** A service of Via medici online www.thieme.de\n",
      "*   **Page 18:** A service of Via medici online www.thie...\n",
      "────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided information, here’s a breakdown of the documents you currently have in your knowledge base:\\n\\n*   **Page 1:** Vishal Rajesh Kushwaha\\n*   **Page 13:** A service of Via medici online www.thieme.de\\n*   **Page 14:** Physics exam spring 2001\\n*   **Page 15:** A service of Via medici online www.thieme.de\\n*   **Page 16:** A service of Via medici online www.thieme.de\\n*   **Page 17:** A service of Via medici online www.thieme.de\\n*   **Page 18:** A service of Via medici online www.thieme.de\\n*   **Page 23:** A service of Via medici online www.thieme.de\\n*   **Page 24:** A service of Via medici online www.thieme.de\\n*   **Page 25:** A service of Via medici online www.thieme.de\\n*   **Page 26:** A service of Via medici online www.thieme.de\\n*   **Page 27:** A service of Via medici online www.thieme.de\\n\\nDo you have any other questions?'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Easy-to-use functions for your Document Q&A system\n",
    "\n",
    "def ask_about_documents(user_question):\n",
    "    \"\"\"Ask any question about the documents you've added\"\"\"\n",
    "    print(f\"❓ {user_question}\")\n",
    "    generated_answer = qa_system.answer_question(user_question)\n",
    "    \n",
    "    # Keep answers readable on screen\n",
    "    if len(generated_answer) > 500:\n",
    "        display_answer = generated_answer[:500] + \"...\"\n",
    "    else:\n",
    "        display_answer = generated_answer\n",
    "    \n",
    "    print(f\"🤖 {display_answer}\")\n",
    "    print(\"─\" * 60)\n",
    "    return generated_answer\n",
    "\n",
    "def add_document_to_system(file_location):\n",
    "    \"\"\"Add a document (PDF, Word, or text file) to your knowledge base\"\"\"\n",
    "    qa_system.add_document_file(file_location)\n",
    "\n",
    "def check_knowledge_base():\n",
    "    \"\"\"See what documents are in your knowledge base\"\"\"\n",
    "    return qa_system.show_knowledge_base_info()\n",
    "\n",
    "# Show current status of the system\n",
    "print(\"📋 Current Knowledge Base Status:\")\n",
    "check_knowledge_base()\n",
    "\n",
    "print(\"\\n💡 How to use your Document Q&A system:\")\n",
    "print(\"• add_document_to_system('path/to/file.pdf')     - Add a document\")\n",
    "print(\"• ask_about_documents('What is this about?')     - Ask questions\")\n",
    "print(\"• check_knowledge_base()                         - See what you have\")\n",
    "\n",
    "print(\"\\n🧪 Quick test:\")\n",
    "ask_about_documents(\"What documents do I currently have in my knowledge base?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5508e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Reading aerz_vorpr_f2001_2a (1).pdf...\n",
      "📝 Processing text: 70274 characters → 22 searchable pieces\n",
      "✅ Added 22 pieces to knowledge base\n",
      "📄 Reading cover letter.pdf...\n",
      "📝 Processing text: 70274 characters → 22 searchable pieces\n",
      "✅ Added 22 pieces to knowledge base\n",
      "📄 Reading cover letter.pdf...\n",
      "📝 Processing text: 2041 characters → 1 searchable pieces\n",
      "✅ Added 1 pieces to knowledge base\n",
      "📊 Knowledge base contains 23 document pieces\n",
      "❓ What is the main topic of these documents?\n",
      "🔍 Searching through 23 document pieces...\n",
      "📝 Processing text: 2041 characters → 1 searchable pieces\n",
      "✅ Added 1 pieces to knowledge base\n",
      "📊 Knowledge base contains 23 document pieces\n",
      "❓ What is the main topic of these documents?\n",
      "🔍 Searching through 23 document pieces...\n",
      "🤖 Based on the provided documents, the main topic is **Health-damaging behaviors**.\n",
      "\n",
      "Here’s a breakdown of how the documents relate to this topic:\n",
      "\n",
      "*   **Early focus on Modeling:** The documents consistently discuss the impact of behavioral patterns, specifically concerning health-damaging behaviors.\n",
      "*   **Focus on consequences:** The text highlights the consequences of these behaviors, such as heart disease, and the need to address them.\n",
      "*   **Model of Health-Related Behavior:** The documents exp...\n",
      "────────────────────────────────────────────────────────────\n",
      "❓ Can you summarize the key points from these documents?\n",
      "🔍 Searching through 23 document pieces...\n",
      "🤖 Based on the provided documents, the main topic is **Health-damaging behaviors**.\n",
      "\n",
      "Here’s a breakdown of how the documents relate to this topic:\n",
      "\n",
      "*   **Early focus on Modeling:** The documents consistently discuss the impact of behavioral patterns, specifically concerning health-damaging behaviors.\n",
      "*   **Focus on consequences:** The text highlights the consequences of these behaviors, such as heart disease, and the need to address them.\n",
      "*   **Model of Health-Related Behavior:** The documents exp...\n",
      "────────────────────────────────────────────────────────────\n",
      "❓ Can you summarize the key points from these documents?\n",
      "🔍 Searching through 23 document pieces...\n",
      "🤖 Okay, here’s a summary of the key points, organized for clarity:\n",
      "\n",
      "**Overall Theme:** The documents explore the psychological impact of anxiety and the challenges faced in treating it, particularly in the context of a patient’s relationship with their doctor. It highlights the difficulties of managing anxiety, the importance of understanding the patient’s experience, and the need for a holistic approach.\n",
      "\n",
      "**Here’s a breakdown of the key points:**\n",
      "\n",
      "*   **Anxiety and the Doctor-Patient Relationship...\n",
      "────────────────────────────────────────────────────────────\n",
      "❓ What type of research or content is discussed?\n",
      "🔍 Searching through 23 document pieces...\n",
      "🤖 Okay, here’s a summary of the key points, organized for clarity:\n",
      "\n",
      "**Overall Theme:** The documents explore the psychological impact of anxiety and the challenges faced in treating it, particularly in the context of a patient’s relationship with their doctor. It highlights the difficulties of managing anxiety, the importance of understanding the patient’s experience, and the need for a holistic approach.\n",
      "\n",
      "**Here’s a breakdown of the key points:**\n",
      "\n",
      "*   **Anxiety and the Doctor-Patient Relationship...\n",
      "────────────────────────────────────────────────────────────\n",
      "❓ What type of research or content is discussed?\n",
      "🔍 Searching through 23 document pieces...\n",
      "🤖 The text describes a research study focusing on nursing staff's personality traits and the impact of a service of Via medici online.\n",
      "\n",
      "Here’s a breakdown of the key aspects:\n",
      "\n",
      "*   **The Study's Focus:** It’s investigating the reasons behind personality differences among nursing staff, aiming to clarify the reasons.\n",
      "*   **The Investigation Method:** The hospital management commissioned an external social science investigation to gather information.\n",
      "*   **The Type of Research:** It’s a **personality...\n",
      "────────────────────────────────────────────────────────────\n",
      "🤖 The text describes a research study focusing on nursing staff's personality traits and the impact of a service of Via medici online.\n",
      "\n",
      "Here’s a breakdown of the key aspects:\n",
      "\n",
      "*   **The Study's Focus:** It’s investigating the reasons behind personality differences among nursing staff, aiming to clarify the reasons.\n",
      "*   **The Investigation Method:** The hospital management commissioned an external social science investigation to gather information.\n",
      "*   **The Type of Research:** It’s a **personality...\n",
      "────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The text describes a research study focusing on nursing staff's personality traits and the impact of a service of Via medici online.\\n\\nHere’s a breakdown of the key aspects:\\n\\n*   **The Study's Focus:** It’s investigating the reasons behind personality differences among nursing staff, aiming to clarify the reasons.\\n*   **The Investigation Method:** The hospital management commissioned an external social science investigation to gather information.\\n*   **The Type of Research:** It’s a **personality assessment study** – specifically, a study using an **Inventory and resignation rates among nursing staff** to identify potential causes.\\n*   **The Content Involved:** The information is related to psychological conditions, such as potential personality traits, which may influence a nurse's behavior and possibly impact their feelings and engagement.\\n\\nEssentially, the text is about understanding personality factors within the nursing profession, prompting a social science investigation to explore the impact on staff well-being and potentially contribute to improvements in the workplace.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Add your documents and test the system\n",
    "\n",
    "# Add your PDF files to the knowledge base\n",
    "add_document_to_system(r\"c:\\Users\\visha\\Downloads\\approval docx\\rag\\aerz_vorpr_f2001_2a (1).pdf\")\n",
    "add_document_to_system(r\"c:\\Users\\visha\\Downloads\\approval docx\\rag\\cover letter.pdf\")\n",
    "\n",
    "# Check what documents we now have\n",
    "check_knowledge_base()\n",
    "\n",
    "# Ask some questions about your documents\n",
    "ask_about_documents(\"What is the main topic of these documents?\")\n",
    "ask_about_documents(\"Can you summarize the key points from these documents?\")\n",
    "ask_about_documents(\"What type of research or content is discussed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn! Add your own documents and ask your own questions\n",
    "\n",
    "# Add your documents (change these file paths to your actual files)\n",
    "# add_document_to_system(\"path/to/your/document.pdf\")\n",
    "# add_document_to_system(\"path/to/another/file.docx\")\n",
    "# add_document_to_system(\"path/to/text/file.txt\")\n",
    "\n",
    "# Ask your own questions about your documents\n",
    "# ask_about_documents(\"What is this document about?\")\n",
    "# ask_about_documents(\"What are the main conclusions?\")\n",
    "# ask_about_documents(\"Can you explain the methodology used?\")\n",
    "# ask_about_documents(\"What are the key findings?\")\n",
    "# ask_about_documents(\"What is this document about?\")\n",
    "# ask_about_documents(\"What are the main conclusions?\")\n",
    "# ask_about_documents(\"Can you explain the methodology?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a3fad24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❓ What is the main topic of the cover letter?\n",
      "🔍 Searching through 23 document pieces...\n",
      "🤖 The cover letter is focused on expressing interest in a position at the company and highlighting Vishal’s skills and experience in machine learning and automation. It emphasizes his expertise in developing intelligent systems for various use cases, including customer behavior, scientific simulation, and model building. The letter also demonstrates his passion for learning and his desire to contribute creatively and precisely to the company's projects.\n",
      "\n",
      "**Therefore, the main topic of the cover le...\n",
      "────────────────────────────────────────────────────────────\n",
      "🤖 The cover letter is focused on expressing interest in a position at the company and highlighting Vishal’s skills and experience in machine learning and automation. It emphasizes his expertise in developing intelligent systems for various use cases, including customer behavior, scientific simulation, and model building. The letter also demonstrates his passion for learning and his desire to contribute creatively and precisely to the company's projects.\n",
      "\n",
      "**Therefore, the main topic of the cover le...\n",
      "────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The cover letter is focused on expressing interest in a position at the company and highlighting Vishal’s skills and experience in machine learning and automation. It emphasizes his expertise in developing intelligent systems for various use cases, including customer behavior, scientific simulation, and model building. The letter also demonstrates his passion for learning and his desire to contribute creatively and precisely to the company's projects.\\n\\n**Therefore, the main topic of the cover letter is his interest in the specific position and his professional background in machine learning and automation.**\\n\\n\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_about_documents(\"What is the main topic of the cover letter?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
